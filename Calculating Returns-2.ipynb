{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculating and saving returns for various years#\n",
    "\n",
    "data_path = \"/home/harshit/Project/2014/\" #Daily closing prices data\n",
    "return_path = \"/home/harshit/Project/Returns/2014/\"\n",
    "risk_free_ret_path = \"/home/harshit/Project/risk_free_ret/2014/\"\n",
    "lis = pd.DataFrame(listdir(data_path),columns = [\"Symbol\"])  #A list of all data files in a year\n",
    "factors= pd.read_csv(\"/home/harshit/Project/allfactors.csv\")\n",
    "risk_free = factors[[\"Date\",\"Rf %\"]]\n",
    "for i in (lis[\"Symbol\"]):\n",
    "    if i == \"renyi_entropy.csv\": continue\n",
    "    if i == \"entropy.csv\": continue\n",
    "    df2 = pd.DataFrame(columns=[\"Date\",\"Return\"])\n",
    "    data = pd.read_csv(data_path+i)\n",
    "    company = i.split('.')[0]\n",
    "    for j in range(len(data)):\n",
    "            date = data.iloc[j][\"Date\"]\n",
    "            previous = data.iloc[j-1][company]\n",
    "            new = data.iloc[j][company]\n",
    "            ret = ((previous-new)/previous)*100\n",
    "            df = pd.DataFrame([[date,ret]],columns=[\"Date\",\"Return\"])\n",
    "            df2 = df2.append(df,ignore_index=True)   # A DF having return data for whole year\n",
    "    df2.at[0, 'Return'] = 0\n",
    "    df2.Date = df2.Date.apply(lambda x: x.replace(\"-\",\"\"))\n",
    "    df2[\"Date\"] = df2[\"Date\"].apply(pd.to_numeric)\n",
    "    df = pd.merge(df2,risk_free,on=\"Date\")\n",
    "    df[\"R-Rf\"] = df[\"Return\"]-df[\"Rf %\"]          # A data_frame having risk free return for the whole year\n",
    "    df=df.drop([\"Return\",\"Rf %\"],axis=1)\n",
    "    df.rename(columns={\"R-Rf\":'Return'}, inplace=True)\n",
    "    df.to_csv(risk_free_ret_path+company+\".csv\",index=False)\n",
    "#    df2.to_csv(return_path+company+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making single file for return of all companies   \n",
    "#Making Dataframe of list of companies\n",
    "ret_path = \"/home/harshit/Project/Returns/2013/\"\n",
    "rf_ret_path = \"/home/harshit/Project/risk_free_ret/2013/\" #risk free return path\n",
    "file = listdir(ret_path)\n",
    "rf_file = listdir(rf_ret_path)\n",
    "file = pd.DataFrame(file,columns=[\"Name\"])\n",
    "rf_file = pd.DataFrame(rf_file,columns=[\"Name\"])\n",
    "#Combining to make single csv for return of all companies in a year\n",
    "combined = pd.read_csv(ret_path+file.iloc[0][\"Name\"])\n",
    "rf_combined = pd.read_csv(rf_ret_path+file.iloc[0][\"Name\"])\n",
    "name = file.iloc[0][\"Name\"]\n",
    "rf_name = rf_file.iloc[0][\"Name\"]\n",
    "#combined=combined.drop(columns=[\"Unnamed: 0\"])\n",
    "combined.rename(columns={'Return':name}, inplace=True)\n",
    "rf_combined.rename(columns={'Return':rf_name}, inplace=True)\n",
    "#combined[\"Date\"] = pd.to_datetime(combined[\"Date\"])\n",
    "for i in range(len(file)):\n",
    "    if i==0:\n",
    "        continue\n",
    "    name = file.iloc[i][\"Name\"]\n",
    "    if any([name== 'continuous_entropy.csv',name=='continuous_renyi_entropy.csv',name=='entropy.csv',\n",
    "            name=='renyi_entropy.csv']):\n",
    "        continue\n",
    "    data = pd.read_csv(ret_path+name)\n",
    "   # data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    data.rename(columns={'Return':name}, inplace=True)\n",
    "    combined = pd.merge_asof(combined,data,on='Date')\n",
    "\n",
    "for i in range(len(file)):\n",
    "    if i==0:\n",
    "        continue\n",
    "    name = file.iloc[i][\"Name\"]\n",
    "    if any([name== 'continuous_entropy.csv',name=='continuous_renyi_entropy.csv',name=='entropy.csv',\n",
    "            name=='renyi_entropy.csv']):\n",
    "        continue\n",
    "    data = pd.read_csv(rf_ret_path+name)\n",
    "   # data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    data.rename(columns={'Return':name}, inplace=True)\n",
    "    rf_combined = pd.merge_asof(combined,data,on='Date')\n",
    "combined\n",
    "rf_combined\n",
    "combined_path = \"/home/harshit/Project/Returns/combined/\"\n",
    "rf_combined_path = \"/home/harshit/Project/risk_free_ret/combined/\"\n",
    "combined.to_csv(combined_path+\"combined2013.csv\",index=False)\n",
    "rf_combined.to_csv(rf_combined_path+\"rf_combined2013.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "\n",
    "#Finding average returns of top and bottom 30 companies\n",
    "previous_entropy = pd.read_csv(\"/home/harshit/Project/2014/entropy.csv\") #reading previous_entropy list to select 30\n",
    "return_path = \"/home/harshit/Project/risk_free_ret/combined/\"\n",
    "returns = pd.read_csv(return_path+\"rf_combined2015.csv\")\n",
    "date = pd.DataFrame(pd.to_datetime(returns[\"Date\"])) \n",
    "ret_ent = date\n",
    "for i in previous_entropy[\"Symbol\"]:\n",
    "    name = i+\".csv\"\n",
    "    if name in returns:                   # taking return of all firms present in entropy list and in next year\n",
    "        ret = pd.DataFrame(returns[i+\".csv\"])\n",
    "        ret = date.merge(ret,left_index=True, right_index=True)\n",
    "        ret_ent = pd.merge_asof(ret_ent,ret,on=\"Date\")\n",
    "# Selecting firms with highest and lowest entropies\n",
    "high_entropy = ret_ent.iloc[:,0:31]\n",
    "low_entropy = ret_ent.iloc[:,-30:]\n",
    "low_entropy = pd.merge(date,low_entropy,left_index=True,right_index=True)\n",
    "\n",
    "#Finding mean of low and high entropy firm returns\n",
    "high_mean = pd.DataFrame(high_entropy.mean(axis=1),columns=[\"high\"])\n",
    "low_mean = pd.DataFrame(low_entropy.mean(axis=1),columns=[\"low\"])\n",
    "avg= pd.merge(date,high_mean,right_index=True,left_index=True).merge(low_mean,right_index=True,left_index=True)\n",
    "\n",
    "#Finding difference of high and low entropy averages\n",
    "diff = pd.DataFrame(avg[\"high\"]-avg[\"low\"],columns=[\"high-low\"]) \n",
    "avg = pd.merge(avg,diff,right_index=True,left_index=True)\n",
    "avg_path = \"/home/harshit/Project/risk_free_ret/averages/\"\n",
    "avg.to_csv(avg_path+\"average2015.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "#Same using renyi_entropy\n",
    "#Finding average returns of top and bottom 30 companies\n",
    "previous_entropy = pd.read_csv(\"/home/harshit/Project/2012/renyi_entropy.csv\") #reading previous_entropy list to select 30\n",
    "return_path = \"/home/harshit/Project/risk_free_ret/combined/\"\n",
    "returns = pd.read_csv(return_path+\"rf_combined2013.csv\")\n",
    "date = pd.DataFrame(pd.to_datetime(returns[\"Date\"])) \n",
    "ret_ent = date\n",
    "for i in previous_entropy[\"Symbol\"]:\n",
    "    name = i+\".csv\"\n",
    "    if name in returns:                   # taking return of all firms present in entropy list and in next year\n",
    "        ret = pd.DataFrame(returns[i+\".csv\"])\n",
    "        ret = date.merge(ret,left_index=True, right_index=True)\n",
    "        ret_ent = pd.merge_asof(ret_ent,ret,on=\"Date\")\n",
    "# Selecting firms with highest and lowest entropies\n",
    "high_entropy = ret_ent.iloc[:,0:31]\n",
    "low_entropy = ret_ent.iloc[:,-30:]\n",
    "low_entropy = pd.merge(date,low_entropy,left_index=True,right_index=True)\n",
    "\n",
    "#Finding mean of low and high entropy firm returns\n",
    "high_mean = pd.DataFrame(high_entropy.mean(axis=1),columns=[\"high\"])\n",
    "low_mean = pd.DataFrame(low_entropy.mean(axis=1),columns=[\"low\"])\n",
    "avg= pd.merge(date,high_mean,right_index=True,left_index=True).merge(low_mean,right_index=True,left_index=True)\n",
    "\n",
    "#Finding difference of high and low entropy averages\n",
    "diff = pd.DataFrame(avg[\"high\"]-avg[\"low\"],columns=[\"high-low\"]) \n",
    "avg = pd.merge(avg,diff,right_index=True,left_index=True)\n",
    "avg_path = \"/home/harshit/Project/risk_free_ret/averages/\"\n",
    "avg.to_csv(avg_path+\"renyi_average2013.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>40.299716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>-0.966757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-2.110980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.334503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>-1.420998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-0.177830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>-1.070468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>-2.804833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>2.402154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>-1.347337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>-0.575735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>0.582848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>0.811348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>0.474959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>3.255740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>-0.882434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>-2.504618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>-0.848042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-01-27</td>\n",
       "      <td>-1.061649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>-1.726559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>2.382291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>-2.618487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>0.923705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>0.695374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>-0.036309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>1.539977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>-0.547686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>0.225213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>-1.275591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>-0.171046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>2.888365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>-0.976553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>-0.112911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>1.838866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>0.204816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>-0.545627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>-0.726874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>-0.311388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>2.458734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>-0.646595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2017-05-16</td>\n",
       "      <td>-1.415378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2017-05-17</td>\n",
       "      <td>-0.232604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>1.777514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2017-05-19</td>\n",
       "      <td>-0.442367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>0.165157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>3.829958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1.511676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>-2.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>-2.376505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>-0.724785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>-1.112062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>-1.522843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>-0.710784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>0.126551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>0.467859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>2.379670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2017-06-07</td>\n",
       "      <td>-0.331043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>0.009999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>0.814959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>0.504083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     Return\n",
       "0    2017-01-02  40.299716\n",
       "1    2017-01-03  -0.966757\n",
       "2    2017-01-04  -2.110980\n",
       "3    2017-01-05  -0.334503\n",
       "4    2017-01-06  -1.420998\n",
       "5    2017-01-09  -0.177830\n",
       "6    2017-01-10  -1.070468\n",
       "7    2017-01-11  -2.804833\n",
       "8    2017-01-12   2.402154\n",
       "9    2017-01-13  -1.347337\n",
       "10   2017-01-16  -0.575735\n",
       "11   2017-01-17   0.582848\n",
       "12   2017-01-18   0.811348\n",
       "13   2017-01-19   0.474959\n",
       "14   2017-01-20   3.255740\n",
       "15   2017-01-23  -0.882434\n",
       "16   2017-01-24  -2.504618\n",
       "17   2017-01-25  -0.848042\n",
       "18   2017-01-27  -1.061649\n",
       "19   2017-01-30  -1.726559\n",
       "20   2017-01-31   2.382291\n",
       "21   2017-02-01  -2.618487\n",
       "22   2017-02-02   0.923705\n",
       "23   2017-02-03   0.695374\n",
       "24   2017-02-06  -0.036309\n",
       "25   2017-02-07   1.539977\n",
       "26   2017-02-08  -0.547686\n",
       "27   2017-02-09   0.225213\n",
       "28   2017-02-10  -1.275591\n",
       "29   2017-02-13  -0.171046\n",
       "..          ...        ...\n",
       "80   2017-05-02   2.888365\n",
       "81   2017-05-03  -0.976553\n",
       "82   2017-05-04  -0.112911\n",
       "83   2017-05-05   1.838866\n",
       "84   2017-05-08   0.204816\n",
       "85   2017-05-09  -0.545627\n",
       "86   2017-05-10  -0.726874\n",
       "87   2017-05-11  -0.311388\n",
       "88   2017-05-12   2.458734\n",
       "89   2017-05-15  -0.646595\n",
       "90   2017-05-16  -1.415378\n",
       "91   2017-05-17  -0.232604\n",
       "92   2017-05-18   1.777514\n",
       "93   2017-05-19  -0.442367\n",
       "94   2017-05-22   0.165157\n",
       "95   2017-05-23   3.829958\n",
       "96   2017-05-24   1.511676\n",
       "97   2017-05-25  -2.000635\n",
       "98   2017-05-26  -2.376505\n",
       "99   2017-05-29  -0.724785\n",
       "100  2017-05-30  -1.112062\n",
       "101  2017-05-31  -1.522843\n",
       "102  2017-06-01  -0.710784\n",
       "103  2017-06-02   0.126551\n",
       "104  2017-06-05   0.467859\n",
       "105  2017-06-06   2.379670\n",
       "106  2017-06-07  -0.331043\n",
       "107  2017-06-08   0.009999\n",
       "108  2017-06-09   0.814959\n",
       "109  2017-06-12   0.504083\n",
       "\n",
       "[110 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
